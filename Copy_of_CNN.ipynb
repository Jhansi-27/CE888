{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Copy of CNN.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jhansi-27/CE888/blob/main/Copy_of_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwRGEQbzGpYQ"
      },
      "source": [
        "# First CNN model for MNIST Dataset\n",
        "\n",
        "* MNIST Dataset is ''Hello World'' of Image Recognition\n",
        "\n",
        "* [Dataset HomePage](http://yann.lecun.com/exdb/mnist/)\n",
        "\n",
        "* History of MNIST Dataset [Watch here](https://www.youtube.com/watch?v=oKzNUGz21JM)\n",
        "\n",
        "\n",
        "---\n",
        "The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a \n",
        "test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.\n",
        "\n",
        "![Kitten](https://camo.githubusercontent.com/01c057a753e92a9bc70b8c45d62b295431851c09cffadf53106fc0aea7e2843f/687474703a2f2f692e7974696d672e636f6d2f76692f3051493378675875422d512f687164656661756c742e6a7067)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhmJOHCpJD_w"
      },
      "source": [
        "# Let's start building our first CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSyHCSV7jymI"
      },
      "source": [
        "from keras import layers\n",
        "from keras import models"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oWNzCYUUjymN"
      },
      "source": [
        "Importantly, a convnet takes as input tensors of shape (image_height, image_width,\n",
        "image_channels) (not including the batch dimension). In this case, we’ll configure\n",
        "the convnet to process inputs of size (28, 28, 1), which is the format of MNIST\n",
        "images. We’ll do this by passing the argument input_shape=(28, 28, 1) to the first\n",
        "layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dM4JLEpwjymN"
      },
      "source": [
        "#### Instantiating a small convnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-OnpExGjymO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ceac294-a765-48fe-8a88-0ae23340d015"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.summary()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "=================================================================\n",
            "Total params: 55,744\n",
            "Trainable params: 55,744\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gcVG3xkjymR"
      },
      "source": [
        "#### Adding a classifier on top of the convnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2DfhDJYjymR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce7cdd80-2544-452a-bdf9-7b4621f29dc3"
      },
      "source": [
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                36928     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 93,322\n",
            "Trainable params: 93,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOKVF4nKjymU"
      },
      "source": [
        "### Training the convnet on MNIST images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIcgUbbUjymV"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnJ2Pfs_jymX"
      },
      "source": [
        "#### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JpHGHE9MjymY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f45f0cba-8e36-48dc-ff1b-b13631fc31c3"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "train_labels[0]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HoTLrfSjymd"
      },
      "source": [
        "#### compile and fit model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i23FDtC9jyme",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2db6692-2004-4c59-8fb4-a58625c9a7d3"
      },
      "source": [
        "model.compile(optimizer='rmsprop', \n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "history = model.fit(train_images, train_labels, epochs=2, batch_size=64, validation_split=0.2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "750/750 [==============================] - 35s 5ms/step - loss: 0.4447 - accuracy: 0.8552 - val_loss: 0.0894 - val_accuracy: 0.9732\n",
            "Epoch 2/2\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.0559 - accuracy: 0.9825 - val_loss: 0.0467 - val_accuracy: 0.9862\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zU8iI5ojymg"
      },
      "source": [
        "#### evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3VeaL1Njymh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efa3b9f1-b81e-4174-b33c-9b15f422bd2d"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "test_acc"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0358 - accuracy: 0.9876\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9876000285148621"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXNZOY7Sjymj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "39577d61-af86-4326-cfe5-35c616487fbd"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsQMc0Iojyml"
      },
      "source": [
        "## Task 1\n",
        "\n",
        "Change the activation function and other parameters such as optimizer to see the effect on the network and it's performance. If possible create a grid search. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owJ-29BrJXNa"
      },
      "source": [
        "# Write code here\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.wrappers.scikit_learn import KerasClassifier"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCm68ERFH3cj"
      },
      "source": [
        "def create_model():\n",
        "\t# create model\n",
        "\t\n",
        "  model = models.Sequential()\n",
        "  model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.MaxPooling2D((2, 2)))\n",
        "  model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "  model.add(layers.Flatten())\n",
        "  model.add(layers.Dense(64, activation='relu'))\n",
        "  model.add(layers.Dense(10, activation='softmax'))\n",
        "\t# Compile model\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPy8VGoWCufM",
        "outputId": "be40b723-339e-4a90-93d3-1fe1dfeda08e"
      },
      "source": [
        "adam_model = create_model()\n",
        "adam_model.fit(train_images,train_labels, epochs=2, batch_size=64, validation_split=0.2)\n",
        "\n",
        "test_loss, test_acc = adam_model.evaluate(test_images, test_labels)\n",
        "test_acc"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "750/750 [==============================] - 4s 5ms/step - loss: 0.5151 - accuracy: 0.8368 - val_loss: 0.0738 - val_accuracy: 0.9770\n",
            "Epoch 2/2\n",
            "750/750 [==============================] - 3s 5ms/step - loss: 0.0634 - accuracy: 0.9803 - val_loss: 0.0532 - val_accuracy: 0.9840\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0472 - accuracy: 0.9838\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9837999939918518"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82YNqSN2KGeR",
        "outputId": "6e017e17-26f4-4f7c-b3da-696614e424a4"
      },
      "source": [
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
        "# define the grid search parameters\n",
        "batch_size = [60, 80, 100]\n",
        "epochs = [5,10]\n",
        "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
        "grid_result = grid.fit(train_images,train_labels)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best score : %f obtained using %s\" % (grid_result.best_score_, grid_result.best_params_),\"\\n\")\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best: 0.988400 using {'batch_size': 60, 'epochs': 10}\n",
            "0.985417 (0.003115) with: {'batch_size': 60, 'epochs': 5}\n",
            "0.988400 (0.000471) with: {'batch_size': 60, 'epochs': 10}\n",
            "0.986450 (0.000860) with: {'batch_size': 80, 'epochs': 5}\n",
            "0.986267 (0.002817) with: {'batch_size': 80, 'epochs': 10}\n",
            "0.986117 (0.001822) with: {'batch_size': 100, 'epochs': 5}\n",
            "0.988267 (0.001043) with: {'batch_size': 100, 'epochs': 10}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfVpxD1wI9vi",
        "outputId": "995831f9-d5d9-4d09-9161-a4cbb20df64e"
      },
      "source": [
        "adam_model2 = create_model()\n",
        "adam_model2.fit(train_images,train_labels, epochs=10, batch_size=60, validation_split=0.2)\n",
        "test_loss, test_acc = adam_model2.evaluate(test_images, test_labels)\n",
        "test_acc"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.4845 - accuracy: 0.8490 - val_loss: 0.0675 - val_accuracy: 0.9799\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0666 - accuracy: 0.9791 - val_loss: 0.0524 - val_accuracy: 0.9848\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0426 - accuracy: 0.9871 - val_loss: 0.0673 - val_accuracy: 0.9797\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0329 - accuracy: 0.9897 - val_loss: 0.0408 - val_accuracy: 0.9881\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0249 - accuracy: 0.9921 - val_loss: 0.0364 - val_accuracy: 0.9893\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0178 - accuracy: 0.9940 - val_loss: 0.0502 - val_accuracy: 0.9860\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0179 - accuracy: 0.9946 - val_loss: 0.0568 - val_accuracy: 0.9854\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0149 - accuracy: 0.9952 - val_loss: 0.0395 - val_accuracy: 0.9895\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0114 - accuracy: 0.9958 - val_loss: 0.0379 - val_accuracy: 0.9898\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0099 - accuracy: 0.9967 - val_loss: 0.0454 - val_accuracy: 0.9885\n",
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0392 - accuracy: 0.9900\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9900000095367432"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lo1ZQVdLdOy",
        "outputId": "def21c00-0587-4ebb-d48e-908ddf883f85"
      },
      "source": [
        "from keras.layers import LeakyReLU\n",
        "activations = ['relu','tanh']\n",
        "\n",
        "for act_function in activations:\n",
        "  print(f\"********** activation function : {act_function} ************** \\n\")\n",
        "  model1 = models.Sequential()\n",
        "  model1.add(layers.Conv2D(32, (3, 3), activation=act_function, input_shape=(28, 28, 1)))\n",
        "  model1.add(layers.MaxPooling2D((2, 2)))\n",
        "  model1.add(layers.Conv2D(64, (3, 3), activation=act_function))\n",
        "  model1.add(layers.MaxPooling2D((2, 2)))\n",
        "  model1.add(layers.Conv2D(64, (3, 3), activation=act_function))\n",
        "  model1.add(layers.Flatten())\n",
        "  model1.add(layers.Dense(64, activation=act_function))\n",
        "  model1.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "  # Compile model\n",
        "  optimizers = ['adam','SGD','adaGrad']\n",
        "  for optimizer in optimizers:\n",
        "    print(optimizer, \":\\n\")\n",
        "    model1.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "    history = model1.fit(train_images,train_labels, epochs=10, batch_size=60, validation_split=0.2)\n",
        "    print(history,\"\\n\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "********** activation function : relu ************** \n",
            "\n",
            "adam :\n",
            "\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.4684 - accuracy: 0.8547 - val_loss: 0.0737 - val_accuracy: 0.9781\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0641 - accuracy: 0.9803 - val_loss: 0.0572 - val_accuracy: 0.9837\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0434 - accuracy: 0.9861 - val_loss: 0.0422 - val_accuracy: 0.9872\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0313 - accuracy: 0.9899 - val_loss: 0.0472 - val_accuracy: 0.9857\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0241 - accuracy: 0.9923 - val_loss: 0.0399 - val_accuracy: 0.9892\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0168 - accuracy: 0.9946 - val_loss: 0.0507 - val_accuracy: 0.9856\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0163 - accuracy: 0.9949 - val_loss: 0.0387 - val_accuracy: 0.9892\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0124 - accuracy: 0.9960 - val_loss: 0.0364 - val_accuracy: 0.9905\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 0.0404 - val_accuracy: 0.9898\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0107 - accuracy: 0.9962 - val_loss: 0.0394 - val_accuracy: 0.9909\n",
            "<tensorflow.python.keras.callbacks.History object at 0x7f0acdd3c590> \n",
            "\n",
            "SGD :\n",
            "\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0037 - accuracy: 0.9988 - val_loss: 0.0359 - val_accuracy: 0.9920\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0030 - accuracy: 0.9991 - val_loss: 0.0360 - val_accuracy: 0.9920\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 0.0358 - val_accuracy: 0.9922\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0018 - accuracy: 0.9996 - val_loss: 0.0362 - val_accuracy: 0.9921\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0016 - accuracy: 0.9996 - val_loss: 0.0363 - val_accuracy: 0.9923\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0018 - accuracy: 0.9995 - val_loss: 0.0367 - val_accuracy: 0.9921\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 0.0367 - val_accuracy: 0.9923\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 0.0367 - val_accuracy: 0.9922\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0010 - accuracy: 0.9997 - val_loss: 0.0372 - val_accuracy: 0.9923\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 9.9536e-04 - accuracy: 0.9999 - val_loss: 0.0372 - val_accuracy: 0.9922\n",
            "<tensorflow.python.keras.callbacks.History object at 0x7f0acdbaa990> \n",
            "\n",
            "adaGrad :\n",
            "\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 8.7792e-04 - accuracy: 0.9999 - val_loss: 0.0374 - val_accuracy: 0.9922\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 9.7789e-04 - accuracy: 0.9999 - val_loss: 0.0374 - val_accuracy: 0.9923\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 9.8758e-04 - accuracy: 0.9999 - val_loss: 0.0375 - val_accuracy: 0.9924\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0376 - val_accuracy: 0.9923\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 9.0728e-04 - accuracy: 0.9998 - val_loss: 0.0376 - val_accuracy: 0.9923\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0377 - val_accuracy: 0.9923\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0012 - accuracy: 0.9997 - val_loss: 0.0378 - val_accuracy: 0.9924\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 8.6523e-04 - accuracy: 0.9999 - val_loss: 0.0378 - val_accuracy: 0.9924\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0379 - val_accuracy: 0.9924\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 9.4110e-04 - accuracy: 0.9999 - val_loss: 0.0380 - val_accuracy: 0.9924\n",
            "<tensorflow.python.keras.callbacks.History object at 0x7f0acca28650> \n",
            "\n",
            "********** activation function : tanh ************** \n",
            "\n",
            "adam :\n",
            "\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 4s 5ms/step - loss: 0.4177 - accuracy: 0.8740 - val_loss: 0.0628 - val_accuracy: 0.9822\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0584 - accuracy: 0.9820 - val_loss: 0.0557 - val_accuracy: 0.9838\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0386 - accuracy: 0.9882 - val_loss: 0.0478 - val_accuracy: 0.9865\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0280 - accuracy: 0.9908 - val_loss: 0.0496 - val_accuracy: 0.9862\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0192 - accuracy: 0.9943 - val_loss: 0.0462 - val_accuracy: 0.9864\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0149 - accuracy: 0.9957 - val_loss: 0.0395 - val_accuracy: 0.9887\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0146 - accuracy: 0.9955 - val_loss: 0.0390 - val_accuracy: 0.9885\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0120 - accuracy: 0.9967 - val_loss: 0.0394 - val_accuracy: 0.9891\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0101 - accuracy: 0.9970 - val_loss: 0.0429 - val_accuracy: 0.9878\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0064 - accuracy: 0.9984 - val_loss: 0.0419 - val_accuracy: 0.9885\n",
            "<tensorflow.python.keras.callbacks.History object at 0x7f0aca86d710> \n",
            "\n",
            "SGD :\n",
            "\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0050 - accuracy: 0.9986 - val_loss: 0.0373 - val_accuracy: 0.9898\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.0367 - val_accuracy: 0.9900\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0035 - accuracy: 0.9995 - val_loss: 0.0365 - val_accuracy: 0.9902\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0026 - accuracy: 0.9997 - val_loss: 0.0362 - val_accuracy: 0.9902\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0358 - val_accuracy: 0.9905\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0025 - accuracy: 0.9997 - val_loss: 0.0357 - val_accuracy: 0.9904\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.0356 - val_accuracy: 0.9904\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0022 - accuracy: 0.9998 - val_loss: 0.0355 - val_accuracy: 0.9907\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.0354 - val_accuracy: 0.9907\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0355 - val_accuracy: 0.9904\n",
            "<tensorflow.python.keras.callbacks.History object at 0x7f0ad5e74510> \n",
            "\n",
            "adaGrad :\n",
            "\n",
            "Epoch 1/10\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0354 - val_accuracy: 0.9907\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0353 - val_accuracy: 0.9908\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0353 - val_accuracy: 0.9907\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.0353 - val_accuracy: 0.9908\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0019 - accuracy: 0.9998 - val_loss: 0.0353 - val_accuracy: 0.9908\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.0353 - val_accuracy: 0.9908\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.0352 - val_accuracy: 0.9908\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0016 - accuracy: 0.9999 - val_loss: 0.0352 - val_accuracy: 0.9908\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0352 - val_accuracy: 0.9908\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0017 - accuracy: 0.9998 - val_loss: 0.0352 - val_accuracy: 0.9908\n",
            "<tensorflow.python.keras.callbacks.History object at 0x7f0b6410b090> \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAJenfb3KaaR",
        "outputId": "5cab11bd-6845-44fe-f864-cb3b5c74a0f2"
      },
      "source": [
        "model1 = models.Sequential()\n",
        "model1.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model1.add(layers.MaxPooling2D((2, 2)))\n",
        "model1.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model1.add(layers.MaxPooling2D((2, 2)))\n",
        "model1.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model1.add(layers.Flatten())\n",
        "model1.add(layers.Dense(64, activation=act_function))\n",
        "model1.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model1.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\n",
        "model1.fit(train_images,train_labels, epochs=10, batch_size=60, validation_split=0.2)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "800/800 [==============================] - 4s 4ms/step - loss: 1.5017 - accuracy: 0.5780 - val_loss: 0.3016 - val_accuracy: 0.9145\n",
            "Epoch 2/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.2905 - accuracy: 0.9179 - val_loss: 0.2022 - val_accuracy: 0.9435\n",
            "Epoch 3/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1958 - accuracy: 0.9438 - val_loss: 0.1509 - val_accuracy: 0.9588\n",
            "Epoch 4/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1506 - accuracy: 0.9565 - val_loss: 0.1227 - val_accuracy: 0.9671\n",
            "Epoch 5/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1225 - accuracy: 0.9651 - val_loss: 0.1101 - val_accuracy: 0.9696\n",
            "Epoch 6/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.1038 - accuracy: 0.9716 - val_loss: 0.0965 - val_accuracy: 0.9727\n",
            "Epoch 7/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0923 - accuracy: 0.9726 - val_loss: 0.0888 - val_accuracy: 0.9741\n",
            "Epoch 8/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0848 - accuracy: 0.9745 - val_loss: 0.0780 - val_accuracy: 0.9768\n",
            "Epoch 9/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0717 - accuracy: 0.9791 - val_loss: 0.0794 - val_accuracy: 0.9752\n",
            "Epoch 10/10\n",
            "800/800 [==============================] - 3s 4ms/step - loss: 0.0715 - accuracy: 0.9791 - val_loss: 0.0715 - val_accuracy: 0.9778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0acff785d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLIoA9wvL2kb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b29c5642-f2d0-46d8-b4d7-8064ced5ba38"
      },
      "source": [
        "test_loss, test_acc = model1.evaluate(test_images, test_labels)\n",
        "test_acc"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0634 - accuracy: 0.9828\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9828000068664551"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}